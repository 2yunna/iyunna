{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHKMfZOfSBKz"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPAp0wj2SBK7"
      },
      "source": [
        "# Fundamentals of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofWS-4dXSBK8"
      },
      "source": [
        "## Generalization: The goal of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI0DrMPtSBK8"
      },
      "source": [
        "### Underfitting and overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B892BZTuSBK9"
      },
      "source": [
        "#### Noisy training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwOLy4kkSBK-"
      },
      "source": [
        "#### Ambiguous features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgJ_Qs-zSBK_"
      },
      "source": [
        "#### Rare features and spurious correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QxbvlIXSBLA"
      },
      "source": [
        "**Adding white-noise channels or all-zeros channels to MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN7n7Ew8SBLB",
        "outputId": "ed7589d5-1cc3-45a6-8b43-8f3ad68263fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "train_images_with_noise_channels = np.concatenate(\n",
        "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
        "\n",
        "train_images_with_zeros_channels = np.concatenate(\n",
        "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU2oZ4MySBLD"
      },
      "source": [
        "**Training the same model on MNIST data with noise channels or all-zero channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbrbUKVFSBLE",
        "outputId": "4d892ef7-a2b4-4a9e-82b1-d49c22651357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.6907 - loss: 1.1090 - val_accuracy: 0.8961 - val_loss: 0.3307\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9140 - loss: 0.2772 - val_accuracy: 0.9392 - val_loss: 0.2033\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9458 - loss: 0.1770 - val_accuracy: 0.9553 - val_loss: 0.1610\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9601 - loss: 0.1277 - val_accuracy: 0.9561 - val_loss: 0.1433\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.0906 - val_accuracy: 0.9603 - val_loss: 0.1405\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9799 - loss: 0.0635 - val_accuracy: 0.9607 - val_loss: 0.1332\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9854 - loss: 0.0486 - val_accuracy: 0.9646 - val_loss: 0.1289\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0343 - val_accuracy: 0.9642 - val_loss: 0.1425\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0228 - val_accuracy: 0.9648 - val_loss: 0.1278\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9948 - loss: 0.0184 - val_accuracy: 0.9675 - val_loss: 0.1249\n",
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8632 - loss: 0.4750 - val_accuracy: 0.9571 - val_loss: 0.1484\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9619 - loss: 0.1313 - val_accuracy: 0.9678 - val_loss: 0.1090\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9764 - loss: 0.0780 - val_accuracy: 0.9711 - val_loss: 0.0928\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9831 - loss: 0.0565 - val_accuracy: 0.9740 - val_loss: 0.0921\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9875 - loss: 0.0411 - val_accuracy: 0.9752 - val_loss: 0.0834\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9918 - loss: 0.0322 - val_accuracy: 0.9704 - val_loss: 0.1000\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9930 - loss: 0.0246 - val_accuracy: 0.9772 - val_loss: 0.0761\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9955 - loss: 0.0179 - val_accuracy: 0.9789 - val_loss: 0.0730\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0130 - val_accuracy: 0.9794 - val_loss: 0.0766\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0099 - val_accuracy: 0.9797 - val_loss: 0.0771\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "history_noise = model.fit(\n",
        "    train_images_with_noise_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)\n",
        "\n",
        "model = get_model()\n",
        "history_zeros = model.fit(\n",
        "    train_images_with_zeros_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWbIiPy4SBLE"
      },
      "source": [
        "**Plotting a validation accuracy comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fldlte_eSBLF",
        "outputId": "d97c458c-8f28-4d3e-8463-3186ec8b3236"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history_ori' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ac7e7a27087d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_acc_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_noise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_acc_zeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_zeros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval_acc_ori\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_ori\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m plt.plot(epochs, val_acc_noise, \"b-\",\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history_ori' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
        "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
        "val_acc_ori = history_ori.history[\"val_accuracy\"]\n",
        "epochs = range(1, 11)\n",
        "plt.plot(epochs, val_acc_noise, \"b-\",\n",
        "         label=\"Validation accuracy with noise channels\")\n",
        "plt.plot(epochs, val_acc_noise, \"b--\",\n",
        "         label=\"Validation accuracy with zeros channels\")\n",
        "plt.title(\"Effect of noise channels on validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ori = build_model()  # 모델 구조는 기존과 동일하다고 가정\n",
        "history_ori = model_ori.fit(\n",
        "    x_train_ori, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    validation_data=(x_val_ori, y_val)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "TrheqiUHcod_",
        "outputId": "501102b7-f7c2-4d33-d43c-a2880e140dfa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_train_ori' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a51848c64a0f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_ori\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 모델 구조는 기존과 동일하다고 가정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history_ori = model_ori.fit(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx_train_ori\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train_ori' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LhUzk-vSBLF"
      },
      "source": [
        "### The nature of generalization in deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ip0WfDTSBLG"
      },
      "source": [
        "**Fitting a MNIST model with randomly shuffled labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_gXt_fISBLG",
        "outputId": "0d30ba76-dfef-44bf-dcd7-2a9399d1c144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1018 - loss: 2.3302 - val_accuracy: 0.1011 - val_loss: 2.3044\n",
            "Epoch 2/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1160 - loss: 2.2976 - val_accuracy: 0.0988 - val_loss: 2.3148\n",
            "Epoch 3/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1291 - loss: 2.2885 - val_accuracy: 0.1061 - val_loss: 2.3143\n",
            "Epoch 4/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.1451 - loss: 2.2760 - val_accuracy: 0.1011 - val_loss: 2.3263\n",
            "Epoch 5/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1515 - loss: 2.2599 - val_accuracy: 0.1029 - val_loss: 2.3361\n",
            "Epoch 6/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1702 - loss: 2.2371 - val_accuracy: 0.0954 - val_loss: 2.3544\n",
            "Epoch 7/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1884 - loss: 2.2127 - val_accuracy: 0.0992 - val_loss: 2.3697\n",
            "Epoch 8/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2028 - loss: 2.1850 - val_accuracy: 0.1021 - val_loss: 2.3857\n",
            "Epoch 9/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2185 - loss: 2.1549 - val_accuracy: 0.0983 - val_loss: 2.4048\n",
            "Epoch 10/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2383 - loss: 2.1199 - val_accuracy: 0.1019 - val_loss: 2.4300\n",
            "Epoch 11/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2544 - loss: 2.0835 - val_accuracy: 0.1009 - val_loss: 2.4571\n",
            "Epoch 12/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2719 - loss: 2.0464 - val_accuracy: 0.1046 - val_loss: 2.4864\n",
            "Epoch 13/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2868 - loss: 2.0094 - val_accuracy: 0.0994 - val_loss: 2.4952\n",
            "Epoch 14/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3107 - loss: 1.9673 - val_accuracy: 0.1023 - val_loss: 2.5376\n",
            "Epoch 15/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3272 - loss: 1.9271 - val_accuracy: 0.0951 - val_loss: 2.5692\n",
            "Epoch 16/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3431 - loss: 1.8838 - val_accuracy: 0.1028 - val_loss: 2.6007\n",
            "Epoch 17/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3595 - loss: 1.8445 - val_accuracy: 0.1035 - val_loss: 2.6533\n",
            "Epoch 18/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3738 - loss: 1.8046 - val_accuracy: 0.1028 - val_loss: 2.6823\n",
            "Epoch 19/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3917 - loss: 1.7616 - val_accuracy: 0.0991 - val_loss: 2.7271\n",
            "Epoch 20/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4044 - loss: 1.7248 - val_accuracy: 0.1014 - val_loss: 2.7671\n",
            "Epoch 21/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4204 - loss: 1.6845 - val_accuracy: 0.1013 - val_loss: 2.7977\n",
            "Epoch 22/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4364 - loss: 1.6505 - val_accuracy: 0.1031 - val_loss: 2.8499\n",
            "Epoch 23/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4479 - loss: 1.6140 - val_accuracy: 0.1058 - val_loss: 2.8834\n",
            "Epoch 24/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4647 - loss: 1.5670 - val_accuracy: 0.1003 - val_loss: 2.9380\n",
            "Epoch 25/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4826 - loss: 1.5327 - val_accuracy: 0.1033 - val_loss: 2.9855\n",
            "Epoch 26/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4932 - loss: 1.4917 - val_accuracy: 0.1021 - val_loss: 3.0475\n",
            "Epoch 27/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5033 - loss: 1.4694 - val_accuracy: 0.1029 - val_loss: 3.0706\n",
            "Epoch 28/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5181 - loss: 1.4285 - val_accuracy: 0.1053 - val_loss: 3.1134\n",
            "Epoch 29/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5264 - loss: 1.4005 - val_accuracy: 0.1032 - val_loss: 3.1493\n",
            "Epoch 30/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5403 - loss: 1.3697 - val_accuracy: 0.1039 - val_loss: 3.2052\n",
            "Epoch 31/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5498 - loss: 1.3449 - val_accuracy: 0.1046 - val_loss: 3.3008\n",
            "Epoch 32/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5625 - loss: 1.3139 - val_accuracy: 0.0985 - val_loss: 3.3332\n",
            "Epoch 33/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5706 - loss: 1.2794 - val_accuracy: 0.1038 - val_loss: 3.3597\n",
            "Epoch 34/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5831 - loss: 1.2499 - val_accuracy: 0.1028 - val_loss: 3.4356\n",
            "Epoch 35/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5944 - loss: 1.2227 - val_accuracy: 0.1008 - val_loss: 3.4887\n",
            "Epoch 36/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6027 - loss: 1.1960 - val_accuracy: 0.1028 - val_loss: 3.5422\n",
            "Epoch 37/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6087 - loss: 1.1687 - val_accuracy: 0.1025 - val_loss: 3.6012\n",
            "Epoch 38/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6201 - loss: 1.1383 - val_accuracy: 0.0993 - val_loss: 3.6783\n",
            "Epoch 39/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6294 - loss: 1.1143 - val_accuracy: 0.1041 - val_loss: 3.7077\n",
            "Epoch 40/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6379 - loss: 1.0964 - val_accuracy: 0.1043 - val_loss: 3.7831\n",
            "Epoch 41/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6418 - loss: 1.0719 - val_accuracy: 0.1041 - val_loss: 3.8323\n",
            "Epoch 42/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6551 - loss: 1.0497 - val_accuracy: 0.1011 - val_loss: 3.8881\n",
            "Epoch 43/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6603 - loss: 1.0273 - val_accuracy: 0.0989 - val_loss: 3.9513\n",
            "Epoch 44/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6671 - loss: 1.0134 - val_accuracy: 0.1019 - val_loss: 4.0433\n",
            "Epoch 45/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6770 - loss: 0.9846 - val_accuracy: 0.1018 - val_loss: 4.1032\n",
            "Epoch 46/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6812 - loss: 0.9669 - val_accuracy: 0.0997 - val_loss: 4.1430\n",
            "Epoch 47/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6935 - loss: 0.9399 - val_accuracy: 0.0989 - val_loss: 4.2546\n",
            "Epoch 48/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7000 - loss: 0.9224 - val_accuracy: 0.0985 - val_loss: 4.2733\n",
            "Epoch 49/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7021 - loss: 0.9087 - val_accuracy: 0.1024 - val_loss: 4.3597\n",
            "Epoch 50/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7150 - loss: 0.8871 - val_accuracy: 0.0982 - val_loss: 4.4452\n",
            "Epoch 51/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7212 - loss: 0.8640 - val_accuracy: 0.0997 - val_loss: 4.4749\n",
            "Epoch 52/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7269 - loss: 0.8480 - val_accuracy: 0.1014 - val_loss: 4.5393\n",
            "Epoch 53/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7295 - loss: 0.8376 - val_accuracy: 0.1002 - val_loss: 4.6035\n",
            "Epoch 54/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7385 - loss: 0.8124 - val_accuracy: 0.1015 - val_loss: 4.6615\n",
            "Epoch 55/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7455 - loss: 0.7963 - val_accuracy: 0.1016 - val_loss: 4.7195\n",
            "Epoch 56/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7516 - loss: 0.7806 - val_accuracy: 0.1005 - val_loss: 4.7616\n",
            "Epoch 57/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7560 - loss: 0.7615 - val_accuracy: 0.0989 - val_loss: 4.8999\n",
            "Epoch 58/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7611 - loss: 0.7495 - val_accuracy: 0.1031 - val_loss: 4.9636\n",
            "Epoch 59/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7631 - loss: 0.7370 - val_accuracy: 0.0972 - val_loss: 5.0054\n",
            "Epoch 60/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7703 - loss: 0.7247 - val_accuracy: 0.1026 - val_loss: 5.0474\n",
            "Epoch 61/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7737 - loss: 0.7092 - val_accuracy: 0.0983 - val_loss: 5.1125\n",
            "Epoch 62/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7814 - loss: 0.6874 - val_accuracy: 0.1007 - val_loss: 5.1500\n",
            "Epoch 63/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7851 - loss: 0.6755 - val_accuracy: 0.0997 - val_loss: 5.2554\n",
            "Epoch 64/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7886 - loss: 0.6649 - val_accuracy: 0.1001 - val_loss: 5.3522\n",
            "Epoch 65/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7918 - loss: 0.6533 - val_accuracy: 0.0979 - val_loss: 5.4094\n",
            "Epoch 66/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8007 - loss: 0.6324 - val_accuracy: 0.0964 - val_loss: 5.4702\n",
            "Epoch 67/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8040 - loss: 0.6163 - val_accuracy: 0.0988 - val_loss: 5.5396\n",
            "Epoch 68/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8091 - loss: 0.6129 - val_accuracy: 0.0997 - val_loss: 5.6336\n",
            "Epoch 69/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8071 - loss: 0.6095 - val_accuracy: 0.1003 - val_loss: 5.7079\n",
            "Epoch 70/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8107 - loss: 0.5947 - val_accuracy: 0.1002 - val_loss: 5.7699\n",
            "Epoch 71/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8207 - loss: 0.5778 - val_accuracy: 0.1013 - val_loss: 5.8417\n",
            "Epoch 72/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8222 - loss: 0.5668 - val_accuracy: 0.1010 - val_loss: 5.8952\n",
            "Epoch 73/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8267 - loss: 0.5556 - val_accuracy: 0.1016 - val_loss: 5.9562\n",
            "Epoch 74/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8322 - loss: 0.5400 - val_accuracy: 0.0998 - val_loss: 6.0526\n",
            "Epoch 75/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8379 - loss: 0.5265 - val_accuracy: 0.1002 - val_loss: 6.1404\n",
            "Epoch 76/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8361 - loss: 0.5245 - val_accuracy: 0.1003 - val_loss: 6.1722\n",
            "Epoch 77/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8395 - loss: 0.5166 - val_accuracy: 0.0977 - val_loss: 6.2612\n",
            "Epoch 78/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8433 - loss: 0.5037 - val_accuracy: 0.0977 - val_loss: 6.3467\n",
            "Epoch 79/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8443 - loss: 0.4989 - val_accuracy: 0.0993 - val_loss: 6.4194\n",
            "Epoch 80/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8485 - loss: 0.4889 - val_accuracy: 0.1007 - val_loss: 6.4765\n",
            "Epoch 81/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8550 - loss: 0.4723 - val_accuracy: 0.1042 - val_loss: 6.5550\n",
            "Epoch 82/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8556 - loss: 0.4674 - val_accuracy: 0.1022 - val_loss: 6.6369\n",
            "Epoch 83/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8594 - loss: 0.4578 - val_accuracy: 0.1021 - val_loss: 6.7427\n",
            "Epoch 84/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8606 - loss: 0.4463 - val_accuracy: 0.1018 - val_loss: 6.7629\n",
            "Epoch 85/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8644 - loss: 0.4405 - val_accuracy: 0.1005 - val_loss: 6.8373\n",
            "Epoch 86/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8678 - loss: 0.4314 - val_accuracy: 0.1012 - val_loss: 6.9704\n",
            "Epoch 87/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8677 - loss: 0.4260 - val_accuracy: 0.1003 - val_loss: 6.9593\n",
            "Epoch 88/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8745 - loss: 0.4108 - val_accuracy: 0.1042 - val_loss: 7.0591\n",
            "Epoch 89/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8725 - loss: 0.4115 - val_accuracy: 0.1002 - val_loss: 7.0964\n",
            "Epoch 90/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8758 - loss: 0.4049 - val_accuracy: 0.1002 - val_loss: 7.2029\n",
            "Epoch 91/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8812 - loss: 0.3891 - val_accuracy: 0.1018 - val_loss: 7.2531\n",
            "Epoch 92/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8826 - loss: 0.3837 - val_accuracy: 0.0992 - val_loss: 7.3181\n",
            "Epoch 93/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8828 - loss: 0.3831 - val_accuracy: 0.1013 - val_loss: 7.4452\n",
            "Epoch 94/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8885 - loss: 0.3688 - val_accuracy: 0.1021 - val_loss: 7.5083\n",
            "Epoch 95/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8901 - loss: 0.3655 - val_accuracy: 0.0995 - val_loss: 7.6086\n",
            "Epoch 96/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8921 - loss: 0.3583 - val_accuracy: 0.0997 - val_loss: 7.6981\n",
            "Epoch 97/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8883 - loss: 0.3587 - val_accuracy: 0.1018 - val_loss: 7.7129\n",
            "Epoch 98/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8969 - loss: 0.3491 - val_accuracy: 0.0983 - val_loss: 7.7920\n",
            "Epoch 99/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8976 - loss: 0.3432 - val_accuracy: 0.1034 - val_loss: 7.8983\n",
            "Epoch 100/100\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8956 - loss: 0.3400 - val_accuracy: 0.1031 - val_loss: 7.9054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e0d99afd010>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "random_train_labels = train_labels[:]\n",
        "np.random.shuffle(random_train_labels)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, random_train_labels,\n",
        "          epochs=100,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEtOxqhDSBLH"
      },
      "source": [
        "#### The manifold hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DAedoXhSBLH"
      },
      "source": [
        "#### Interpolation as a source of generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21swfZGeSBLH"
      },
      "source": [
        "#### Why deep learning works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFnc3FTxSBLI"
      },
      "source": [
        "#### Training data is paramount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXHWcIBKSBLI"
      },
      "source": [
        "## Evaluating machine-learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXPniyuGSBLI"
      },
      "source": [
        "### Training, validation, and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTHK211USBLI"
      },
      "source": [
        "#### Simple hold-out validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIpgeRjgSBLJ"
      },
      "source": [
        "#### K-fold validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsiOhjT_SBLJ"
      },
      "source": [
        "#### Iterated K-fold validation with shuffling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_U2DET-SBLJ"
      },
      "source": [
        "### Beating a common-sense baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0_kxcmlSBLJ"
      },
      "source": [
        "### Things to keep in mind about model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_-fupC9SBLK"
      },
      "source": [
        "## Improving model fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkVx-wySSBLK"
      },
      "source": [
        "### Tuning key gradient descent parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxwrG5HoSBLK"
      },
      "source": [
        "**Training a MNIST model with an incorrectly high learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S4f1aftSBLK",
        "outputId": "3a98423a-56fa-4deb-cc1f-e43b3f931c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4353 - loss: 3853.6729 - val_accuracy: 0.2093 - val_loss: 2.0937\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1965 - loss: 2.5791 - val_accuracy: 0.1441 - val_loss: 2.3522\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.1733 - loss: 2.5703 - val_accuracy: 0.2387 - val_loss: 2.3007\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1977 - loss: 2.3445 - val_accuracy: 0.1773 - val_loss: 2.2959\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1677 - loss: 2.4638 - val_accuracy: 0.1385 - val_loss: 2.2759\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1594 - loss: 2.3871 - val_accuracy: 0.1313 - val_loss: 2.4348\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1598 - loss: 2.3470 - val_accuracy: 0.1802 - val_loss: 2.3039\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1745 - loss: 2.3429 - val_accuracy: 0.2089 - val_loss: 2.1392\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1952 - loss: 2.3994 - val_accuracy: 0.2096 - val_loss: 3.2485\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2072 - loss: 2.4328 - val_accuracy: 0.2204 - val_loss: 2.1673\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e0d994c83d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAqtzgRzSBLL"
      },
      "source": [
        "**The same model with a more appropriate learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFhTZekdSBLL",
        "outputId": "4050f76c-75cb-40f5-f9ea-e49eeb83eca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8340 - loss: 0.9124 - val_accuracy: 0.9582 - val_loss: 0.1470\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9642 - loss: 0.1236 - val_accuracy: 0.9628 - val_loss: 0.1443\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9740 - loss: 0.0936 - val_accuracy: 0.9630 - val_loss: 0.1629\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0719 - val_accuracy: 0.9708 - val_loss: 0.1407\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9844 - loss: 0.0613 - val_accuracy: 0.9724 - val_loss: 0.1603\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0542 - val_accuracy: 0.9743 - val_loss: 0.1651\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9880 - loss: 0.0532 - val_accuracy: 0.9732 - val_loss: 0.1932\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0502 - val_accuracy: 0.9723 - val_loss: 0.2281\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 0.0374 - val_accuracy: 0.9732 - val_loss: 0.2103\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0375 - val_accuracy: 0.9758 - val_loss: 0.2051\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e0d81bac550>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKevUh-cSBLM"
      },
      "source": [
        "### Leveraging better architecture priors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxusLlgKSBLM"
      },
      "source": [
        "### Increasing model capacity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JxZKCaGSBLM"
      },
      "source": [
        "**A simple logistic regression on MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4R4nXY2SBLN",
        "outputId": "92abfe45-c2bd-4524-e222-15353c349761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 1.0345 - val_accuracy: 0.9047 - val_loss: 0.3587\n",
            "Epoch 2/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.3671 - val_accuracy: 0.9154 - val_loss: 0.3088\n",
            "Epoch 3/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.3234 - val_accuracy: 0.9185 - val_loss: 0.2918\n",
            "Epoch 4/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2999 - val_accuracy: 0.9225 - val_loss: 0.2830\n",
            "Epoch 5/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.3001 - val_accuracy: 0.9240 - val_loss: 0.2802\n",
            "Epoch 6/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.2842 - val_accuracy: 0.9255 - val_loss: 0.2730\n",
            "Epoch 7/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2730 - val_accuracy: 0.9255 - val_loss: 0.2710\n",
            "Epoch 8/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.2713 - val_accuracy: 0.9273 - val_loss: 0.2692\n",
            "Epoch 9/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2765 - val_accuracy: 0.9278 - val_loss: 0.2674\n",
            "Epoch 10/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2724 - val_accuracy: 0.9293 - val_loss: 0.2667\n",
            "Epoch 11/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2665 - val_accuracy: 0.9298 - val_loss: 0.2661\n",
            "Epoch 12/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2705 - val_accuracy: 0.9281 - val_loss: 0.2650\n",
            "Epoch 13/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2690 - val_accuracy: 0.9287 - val_loss: 0.2653\n",
            "Epoch 14/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2582 - val_accuracy: 0.9295 - val_loss: 0.2633\n",
            "Epoch 15/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2693 - val_accuracy: 0.9294 - val_loss: 0.2644\n",
            "Epoch 16/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2649 - val_accuracy: 0.9290 - val_loss: 0.2629\n",
            "Epoch 17/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2557 - val_accuracy: 0.9297 - val_loss: 0.2629\n",
            "Epoch 18/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9292 - loss: 0.2585 - val_accuracy: 0.9299 - val_loss: 0.2626\n",
            "Epoch 19/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.2523 - val_accuracy: 0.9303 - val_loss: 0.2615\n",
            "Epoch 20/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.2491 - val_accuracy: 0.9291 - val_loss: 0.2634\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_small_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "O3rt23eISBLN",
        "outputId": "4ca562ed-77f4-4bd5-dde0-1f1b26684e45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7e0d8c149ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_loss = history_small_model.history[\"val_loss\"]\n",
        "epochs = range(1, 21)\n",
        "plt.plot(epochs, val_loss, \"b--\",\n",
        "         label=\"Validation loss\")\n",
        "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHYNVDpgSBLN",
        "outputId": "b46321f5-9f2a-4e6b-b124-1eafdc395a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.6381 - val_accuracy: 0.9383 - val_loss: 0.2045\n",
            "Epoch 2/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1784 - val_accuracy: 0.9592 - val_loss: 0.1390\n",
            "Epoch 3/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.1220 - val_accuracy: 0.9640 - val_loss: 0.1174\n",
            "Epoch 4/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.0914 - val_accuracy: 0.9686 - val_loss: 0.1032\n",
            "Epoch 5/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.0750 - val_accuracy: 0.9706 - val_loss: 0.1007\n",
            "Epoch 6/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0596 - val_accuracy: 0.9712 - val_loss: 0.0994\n",
            "Epoch 7/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0475 - val_accuracy: 0.9700 - val_loss: 0.1057\n",
            "Epoch 8/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0376 - val_accuracy: 0.9753 - val_loss: 0.0920\n",
            "Epoch 9/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0336 - val_accuracy: 0.9755 - val_loss: 0.0957\n",
            "Epoch 10/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0269 - val_accuracy: 0.9758 - val_loss: 0.0914\n",
            "Epoch 11/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0231 - val_accuracy: 0.9762 - val_loss: 0.0958\n",
            "Epoch 12/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0195 - val_accuracy: 0.9773 - val_loss: 0.0929\n",
            "Epoch 13/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0159 - val_accuracy: 0.9762 - val_loss: 0.0997\n",
            "Epoch 14/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0132 - val_accuracy: 0.9769 - val_loss: 0.1041\n",
            "Epoch 15/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0113 - val_accuracy: 0.9765 - val_loss: 0.1071\n",
            "Epoch 16/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0104 - val_accuracy: 0.9758 - val_loss: 0.1102\n",
            "Epoch 17/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0080 - val_accuracy: 0.9771 - val_loss: 0.1171\n",
            "Epoch 18/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0076 - val_accuracy: 0.9769 - val_loss: 0.1158\n",
            "Epoch 19/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9748 - val_loss: 0.1344\n",
            "Epoch 20/20\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 0.9772 - val_loss: 0.1286\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_large_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "과적합된 버전에선 그래프가 상승"
      ],
      "metadata": {
        "id": "pVWolbbqfpkj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihz2rcxtSBLW"
      },
      "source": [
        "## Improving generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1sKi--zSBLX"
      },
      "source": [
        "### Dataset curation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t14f4O9nSBLX"
      },
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6P5KLsiSBLY"
      },
      "source": [
        "### Using early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwgG7b6CSBLY"
      },
      "source": [
        "### Regularizing your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQR0ik5eSBLY"
      },
      "source": [
        "#### Reducing the network's size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d12oJILHSBLZ"
      },
      "source": [
        "**Original model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjkDff6OSBLZ",
        "outputId": "760f61f6-3c6c-4430-d625-8317c4e2d2b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.6773 - loss: 0.6218 - val_accuracy: 0.8249 - val_loss: 0.4453\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8763 - loss: 0.3805 - val_accuracy: 0.8801 - val_loss: 0.3312\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9135 - loss: 0.2705 - val_accuracy: 0.8831 - val_loss: 0.2994\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9311 - loss: 0.2170 - val_accuracy: 0.8847 - val_loss: 0.2858\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9442 - loss: 0.1775 - val_accuracy: 0.8791 - val_loss: 0.3000\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9522 - loss: 0.1507 - val_accuracy: 0.8886 - val_loss: 0.2806\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9615 - loss: 0.1260 - val_accuracy: 0.8869 - val_loss: 0.2867\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9678 - loss: 0.1115 - val_accuracy: 0.8857 - val_loss: 0.2987\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9735 - loss: 0.0942 - val_accuracy: 0.8806 - val_loss: 0.3305\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9774 - loss: 0.0822 - val_accuracy: 0.8798 - val_loss: 0.3411\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9844 - loss: 0.0670 - val_accuracy: 0.8787 - val_loss: 0.3567\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9881 - loss: 0.0595 - val_accuracy: 0.8720 - val_loss: 0.4092\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9906 - loss: 0.0495 - val_accuracy: 0.8770 - val_loss: 0.3927\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9915 - loss: 0.0425 - val_accuracy: 0.8750 - val_loss: 0.4174\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9942 - loss: 0.0365 - val_accuracy: 0.8728 - val_loss: 0.4353\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9954 - loss: 0.0290 - val_accuracy: 0.8748 - val_loss: 0.4483\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0239 - val_accuracy: 0.8723 - val_loss: 0.4932\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9979 - loss: 0.0188 - val_accuracy: 0.8731 - val_loss: 0.4956\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9978 - loss: 0.0165 - val_accuracy: 0.8735 - val_loss: 0.5228\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9987 - loss: 0.0133 - val_accuracy: 0.8733 - val_loss: 0.5426\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "train_data = vectorize_sequences(train_data)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_original = model.fit(train_data, train_labels,\n",
        "                             epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HexA9qbHSBLZ"
      },
      "source": [
        "**Version of the model with lower capacity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKH-ePwGSBLa",
        "outputId": "3651bfbf-78ed-4848-a68c-8e68da1433d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6821 - loss: 0.6247 - val_accuracy: 0.8479 - val_loss: 0.4555\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8801 - loss: 0.4083 - val_accuracy: 0.8798 - val_loss: 0.3629\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9063 - loss: 0.3125 - val_accuracy: 0.8817 - val_loss: 0.3210\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9270 - loss: 0.2499 - val_accuracy: 0.8897 - val_loss: 0.2909\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9368 - loss: 0.2125 - val_accuracy: 0.8926 - val_loss: 0.2786\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9428 - loss: 0.1868 - val_accuracy: 0.8933 - val_loss: 0.2736\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9529 - loss: 0.1604 - val_accuracy: 0.8923 - val_loss: 0.2723\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9577 - loss: 0.1452 - val_accuracy: 0.8916 - val_loss: 0.2752\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9654 - loss: 0.1252 - val_accuracy: 0.8882 - val_loss: 0.2841\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9688 - loss: 0.1153 - val_accuracy: 0.8872 - val_loss: 0.2903\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9707 - loss: 0.1043 - val_accuracy: 0.8854 - val_loss: 0.2980\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9779 - loss: 0.0900 - val_accuracy: 0.8862 - val_loss: 0.3058\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9791 - loss: 0.0840 - val_accuracy: 0.8826 - val_loss: 0.3224\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9794 - loss: 0.0780 - val_accuracy: 0.8840 - val_loss: 0.3302\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9862 - loss: 0.0650 - val_accuracy: 0.8823 - val_loss: 0.3446\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9870 - loss: 0.0595 - val_accuracy: 0.8802 - val_loss: 0.3575\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9901 - loss: 0.0525 - val_accuracy: 0.8766 - val_loss: 0.3798\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9902 - loss: 0.0486 - val_accuracy: 0.8766 - val_loss: 0.3971\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9925 - loss: 0.0404 - val_accuracy: 0.8753 - val_loss: 0.4138\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9932 - loss: 0.0369 - val_accuracy: 0.8765 - val_loss: 0.4216\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_smaller_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcE1fuaOSBLa"
      },
      "source": [
        "**Version of the model with higher capacity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjUGYkePSBLa",
        "outputId": "d28bd706-753b-4849-9bf4-c0a80e514e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 258ms/step - accuracy: 0.6422 - loss: 0.6392 - val_accuracy: 0.8692 - val_loss: 0.3369\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 251ms/step - accuracy: 0.8656 - loss: 0.3399 - val_accuracy: 0.8854 - val_loss: 0.2806\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 251ms/step - accuracy: 0.9063 - loss: 0.2392 - val_accuracy: 0.8881 - val_loss: 0.2727\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.9278 - loss: 0.1836 - val_accuracy: 0.8566 - val_loss: 0.3443\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 246ms/step - accuracy: 0.9498 - loss: 0.1392 - val_accuracy: 0.8893 - val_loss: 0.2711\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.9723 - loss: 0.0919 - val_accuracy: 0.8718 - val_loss: 0.3688\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - accuracy: 0.9783 - loss: 0.0715 - val_accuracy: 0.8858 - val_loss: 0.3270\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 238ms/step - accuracy: 0.9905 - loss: 0.0444 - val_accuracy: 0.8844 - val_loss: 0.3191\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.9982 - loss: 0.0197 - val_accuracy: 0.8823 - val_loss: 0.4189\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.9876 - loss: 0.0582 - val_accuracy: 0.8842 - val_loss: 0.3825\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 189ms/step - accuracy: 0.9996 - loss: 0.0083 - val_accuracy: 0.8848 - val_loss: 0.4713\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - accuracy: 0.9992 - loss: 0.0061 - val_accuracy: 0.8379 - val_loss: 0.7350\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 197ms/step - accuracy: 0.9913 - loss: 0.0205 - val_accuracy: 0.8840 - val_loss: 0.4918\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - accuracy: 0.9999 - loss: 0.0026 - val_accuracy: 0.8839 - val_loss: 0.5619\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8833 - val_loss: 0.6210\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 7.5163e-04 - val_accuracy: 0.8836 - val_loss: 0.6578\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 4.8865e-04 - val_accuracy: 0.8835 - val_loss: 0.6863\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 3.6438e-04 - val_accuracy: 0.8842 - val_loss: 0.7126\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 2.3343e-04 - val_accuracy: 0.8831 - val_loss: 0.7327\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 1.9544e-04 - val_accuracy: 0.8831 - val_loss: 0.7497\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_larger_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwTYdVtDSBLb"
      },
      "source": [
        "#### Adding weight regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC1gvi-ISBLb"
      },
      "source": [
        "**Adding L2 weight regularization to the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSV2eTI2SBLc",
        "outputId": "6a288549-2171-4119-e4f2-3bc57409a0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.6868 - loss: 0.7036 - val_accuracy: 0.8694 - val_loss: 0.4930\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8875 - loss: 0.4463 - val_accuracy: 0.8812 - val_loss: 0.4076\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9120 - loss: 0.3501 - val_accuracy: 0.8794 - val_loss: 0.3827\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9284 - loss: 0.3053 - val_accuracy: 0.8890 - val_loss: 0.3600\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9367 - loss: 0.2809 - val_accuracy: 0.8698 - val_loss: 0.3926\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9353 - loss: 0.2681 - val_accuracy: 0.8847 - val_loss: 0.3624\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9417 - loss: 0.2544 - val_accuracy: 0.8829 - val_loss: 0.3687\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9482 - loss: 0.2443 - val_accuracy: 0.8820 - val_loss: 0.3690\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9475 - loss: 0.2378 - val_accuracy: 0.8738 - val_loss: 0.3966\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9562 - loss: 0.2243 - val_accuracy: 0.8828 - val_loss: 0.3697\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9590 - loss: 0.2200 - val_accuracy: 0.8814 - val_loss: 0.3826\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9570 - loss: 0.2154 - val_accuracy: 0.8799 - val_loss: 0.3797\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9601 - loss: 0.2132 - val_accuracy: 0.8795 - val_loss: 0.3862\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9613 - loss: 0.2061 - val_accuracy: 0.8712 - val_loss: 0.4234\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9642 - loss: 0.2057 - val_accuracy: 0.8771 - val_loss: 0.3987\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9657 - loss: 0.1996 - val_accuracy: 0.8771 - val_loss: 0.3982\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9675 - loss: 0.1954 - val_accuracy: 0.8643 - val_loss: 0.4475\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9584 - loss: 0.2069 - val_accuracy: 0.8726 - val_loss: 0.4244\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9674 - loss: 0.1926 - val_accuracy: 0.8737 - val_loss: 0.4233\n",
            "Epoch 20/20\n",
            "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9664 - loss: 0.1931"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_l2_reg = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0kfi_zzSBLc"
      },
      "source": [
        "**Different weight regularizers available in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFK76wgISBLc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "regularizers.l1(0.001)\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujzZiQXRSBLd"
      },
      "source": [
        "#### Adding dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgJuMiDbSBLd"
      },
      "source": [
        "**Adding dropout to the IMDB model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_ouxl4rSBLd"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_dropout = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_CRdvNYSBLe"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter05_fundamentals-of-ml.i",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}